{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de textos (TRAIN):\n",
      "25000\n",
      "Total de textos (TEST):\n",
      "25000\n",
      "\n",
      "Total de textos com avaliação POSITIVE\n",
      "12500\n",
      "3154_10.txt\n",
      "1760_10.txt\n",
      "8067_8.txt\n",
      "6038_10.txt\n",
      "6447_8.txt\n",
      "\n",
      "Total de textos com avaliação NEGATIVE\n",
      "12500\n",
      "8466_1.txt\n",
      "7084_1.txt\n",
      "1102_3.txt\n",
      "1389_2.txt\n",
      "2857_1.txt\n"
     ]
    }
   ],
   "source": [
    "PATHS = {\n",
    "    'TRAIN' : {\n",
    "        'POSITIVE' : './IMDB_dataset/train/pos',\n",
    "        'NEGATIVE' : './IMDB_dataset/train/neg'\n",
    "    },\n",
    "    'TEST' : {\n",
    "        'POSITIVE' : './IMDB_dataset/test/pos',\n",
    "        'NEGATIVE' : './IMDB_dataset/test/neg'\n",
    "    }\n",
    "}\n",
    "\n",
    "documents_amount = {\n",
    "    'TRAIN' : {\n",
    "        'POSITIVE' : len(os.listdir(PATHS['TRAIN']['POSITIVE'])),\n",
    "        'NEGATIVE' : len(os.listdir(PATHS['TRAIN']['NEGATIVE']))\n",
    "    }, \n",
    "    'TEST' : {\n",
    "        'POSITIVE' : len(os.listdir(PATHS['TEST']['POSITIVE'])),\n",
    "        'NEGATIVE' : len(os.listdir(PATHS['TEST']['NEGATIVE']))\n",
    "    }\n",
    "}\n",
    "\n",
    "total_documents = {\n",
    "    'TRAIN' : sum(documents_amount['TRAIN'].values()),\n",
    "    'TEST'  : sum(documents_amount['TEST'].values())\n",
    "}\n",
    "\n",
    "classes = {\n",
    "    'POSITIVE' : {\n",
    "        'WORDS' : [],\n",
    "        'FREQUENCY' : {},\n",
    "        'PRIOR': 1\n",
    "    },\n",
    "    'NEGATIVE' : {\n",
    "        'WORDS' : [],\n",
    "        'FREQUENCY' : {},\n",
    "        'PRIOR': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "for tipo, total in total_documents.items():\n",
    "    print(f\"Total de textos ({tipo}):\\n{total}\")\n",
    "\n",
    "for classe in classes.keys():\n",
    "    print(f\"\\nTotal de textos com avaliação {classe}\\n{documents_amount['TRAIN'][classe]}\")\n",
    "    for fileName in os.listdir(PATHS['TRAIN'][classe])[0:5]:\n",
    "        print(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+\"\n",
    "CORPUS_USE_PERCENTAGE = 0.1 # usando 100%, treino demora +-35 min\n",
    "\n",
    "def get_document_words(document_path):\n",
    "    content = open(document_path, 'r').read().lower()\n",
    "    return set(re.findall(regex, content))\n",
    "\n",
    "def update_document(dir, words_list):\n",
    "    for i in range(0, int(len(os.listdir(dir))*CORPUS_USE_PERCENTAGE)):\n",
    "        file_name = os.listdir(dir)[i]\n",
    "        words    = get_document_words(dir+\"/\"+file_name)\n",
    "        words_list.extend(words)\n",
    "\n",
    "# for classe in classes.keys():\n",
    "#     update_document(PATHS['TRAIN'][classe], classes[classe]['WORDS'])\n",
    "#     print(f\"Quantidade de palavras nos documentos {classe}:\\n{len(classes[classe]['WORDS'])}\") \n",
    "\n",
    "# print(\"Resultado da extração:\\n{}\".format(documents[\"3154_10.txt\"]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateFrequency(frequency, words):\n",
    "    for word in set(words):\n",
    "        frequency[word] = words.count(word)\n",
    "\n",
    "# for classe in classes.keys():\n",
    "#     updateFrequency(classes[classe]['FREQUENCY'], classes[classe]['WORDS'])\n",
    "#     print(f\"Frequência da palavra FUNNY na classe {classe}:\\n{classes[classe]['FREQUENCY']['funny']}\")\n",
    "\n",
    "# vocabulay = set().union(*documents.values())\n",
    "# print(len(vocabulay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAPLACIAN_SMOOTHING = 1\n",
    "\n",
    "def likelihood_word_class(word, classe):\n",
    "    count_word_class = 0\n",
    "    if (word in classes[classe]['FREQUENCY']):\n",
    "        count_word_class = classes[classe]['FREQUENCY'][word]\n",
    "    \n",
    "    total_words_class = len(classes[classe]['WORDS'])\n",
    "    \n",
    "    return (count_word_class + LAPLACIAN_SMOOTHING)/((LAPLACIAN_SMOOTHING + 1) * total_words_class)\n",
    "\n",
    "def likelihood_doc_class(doc_path):\n",
    "    likelihood = {}\n",
    "                            \n",
    "    for classe in classes.keys():\n",
    "        likelihood[classe] = 1\n",
    "                            \n",
    "        for word in get_document_words(doc_path):\n",
    "            likelihood[classe] *= likelihood_word_class(word, classe)\n",
    "    \n",
    "    return max(likelihood, key=likelihood.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():    \n",
    "    for classe in classes.keys():\n",
    "        update_document(PATHS['TRAIN'][classe], classes[classe]['WORDS'])\n",
    "        updateFrequency(classes[classe]['FREQUENCY'], classes[classe]['WORDS'])\n",
    "        classes[classe]['PRIOR'] = documents_amount['TRAIN'][classe]/total_documents['TRAIN']\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 5.804%\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    correct_tests = 0\n",
    "                            \n",
    "    for classe in classes.keys():\n",
    "        path = PATHS['TEST'][classe]\n",
    "        \n",
    "        for i in range(0, int(len(os.listdir(path))*CORPUS_USE_PERCENTAGE)):\n",
    "            file_name = os.listdir(path)[i]\n",
    "            if (classe == likelihood_doc_class(path+\"/\"+file_name)):\n",
    "                correct_tests += 1\n",
    "                            \n",
    "    print(f\"Accuracy = {100*correct_tests/total_documents['TEST']}%\")\n",
    "        \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
