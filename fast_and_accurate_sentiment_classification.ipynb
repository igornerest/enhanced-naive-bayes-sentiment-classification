{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de textos (TRAIN):\n",
      "25000\n",
      "Total de textos (TEST):\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "PATHS = {\n",
    "    'TRAIN' : {\n",
    "        'POSITIVE' : './IMDB_dataset/train/pos',\n",
    "        'NEGATIVE' : './IMDB_dataset/train/neg'\n",
    "    },\n",
    "    'TEST' : {\n",
    "        'POSITIVE' : './IMDB_dataset/test/pos',\n",
    "        'NEGATIVE' : './IMDB_dataset/test/neg'\n",
    "    }\n",
    "}\n",
    "\n",
    "documents_amount = {\n",
    "    'TRAIN' : {\n",
    "        'POSITIVE' : len(os.listdir(PATHS['TRAIN']['POSITIVE'])),\n",
    "        'NEGATIVE' : len(os.listdir(PATHS['TRAIN']['NEGATIVE']))\n",
    "    }, \n",
    "    'TEST' : {\n",
    "        'POSITIVE' : len(os.listdir(PATHS['TEST']['POSITIVE'])),\n",
    "        'NEGATIVE' : len(os.listdir(PATHS['TEST']['NEGATIVE']))\n",
    "    }\n",
    "}\n",
    "\n",
    "total_documents = {\n",
    "    'TRAIN' : sum(documents_amount['TRAIN'].values()),\n",
    "    'TEST'  : sum(documents_amount['TEST'].values())\n",
    "}\n",
    "\n",
    "classes = {\n",
    "    'POSITIVE' : {\n",
    "        'docs' : {},\n",
    "        'WORDS' : [],\n",
    "        'FREQUENCY' : {},\n",
    "        'PRIOR': 0\n",
    "    },\n",
    "    'NEGATIVE' : {\n",
    "        'docs' : {},\n",
    "        'WORDS' : [],\n",
    "        'FREQUENCY' : {},\n",
    "        'PRIOR': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "for tipo, total in total_documents.items():\n",
    "    print(f\"Total de textos ({tipo}):\\n{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+|[.,;!?]\"\n",
    "CORPUS_USE_PERCENTAGE = 0.05\n",
    "\n",
    "def get_document_words(document_path):\n",
    "    content = open(document_path, 'r').read().lower()\n",
    "    return negation_handling(re.findall(regex, content))\n",
    "\n",
    "def update_words_list(path, words_list):\n",
    "    for i in range(0, int(len(os.listdir(path))*CORPUS_USE_PERCENTAGE)):\n",
    "        file_name = os.listdir(path)[i]\n",
    "        words     = get_document_words(path+\"/\"+file_name)\n",
    "        words_list.extend(words)\n",
    "\n",
    "def update_frequency(frequency, words):\n",
    "    for word in set(words):\n",
    "        frequency[word] = words.count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negation Handling\n",
    "punctuationRe = r\"[,.;!?]\"\n",
    "negationRe = r\"not|no|\\w*n't\"\n",
    "\n",
    "def negation_handling(words):\n",
    "    negated = False\n",
    "    words_set = set()\n",
    "\n",
    "    for word in words:\n",
    "        if (re.fullmatch(punctuationRe, word)):\n",
    "            negated = False\n",
    "            continue\n",
    "        if (re.fullmatch(negationRe, word)):\n",
    "            negated = not negated\n",
    "            continue\n",
    "        if (negated):\n",
    "            word = \"not_\" + word\n",
    "        words_set.add(word)\n",
    "            \n",
    "    return words_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAPLACIAN_SMOOTHING = 1\n",
    "\n",
    "def likelihood_word_class(word, classe):\n",
    "    count_word_class = 0\n",
    "    if (word in classes[classe]['FREQUENCY']):\n",
    "        count_word_class = classes[classe]['FREQUENCY'][word]\n",
    "    \n",
    "    total_words_class = len(classes[classe]['WORDS'])\n",
    "    \n",
    "    return (count_word_class + LAPLACIAN_SMOOTHING)/((LAPLACIAN_SMOOTHING + 1) * total_words_class)\n",
    "\n",
    "def likelihood_doc_class(doc_path, classe):                            \n",
    "    likelihood = 0\n",
    "\n",
    "    for word in get_document_words(doc_path):\n",
    "        likelihood +=  math.log(likelihood_word_class(word, classe))\n",
    "    \n",
    "    return likelihood + classes[classe]['PRIOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train:\n",
    "#     average time @ core i7, 7th gen\n",
    "#     (x%  corpus: y min)\n",
    "#     10% : 03 min)\n",
    "#     20% : 08 min)\n",
    "#     25% : 13 min)\n",
    "#     33% : 19 min)\n",
    "#     50% :+40 min)\n",
    "#    100% :  ? min)\n",
    "\n",
    "for classe in classes:\n",
    "    classes[classe]['PRIOR'] = math.log(documents_amount['TRAIN'][classe]/total_documents['TRAIN'])\n",
    "    update_words_list(PATHS['TRAIN'][classe], classes[classe]['WORDS'])\n",
    "    update_frequency(classes[classe]['FREQUENCY'], classes[classe]['WORDS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (POSITIVE) = 75.744%\n",
      "\n",
      "Accuracy (NEGATIVE) = 85.384%\n",
      "\n",
      "Accuracy (average) = 80.564%\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "def test(classe, total_documents):\n",
    "    correct_tests = 0\n",
    "\n",
    "    path = PATHS['TEST'][classe]\n",
    "    for file_name in os.listdir(path):\n",
    "          likelihood = {}\n",
    "          \n",
    "          for classe_aux in classes:\n",
    "              likelihood[classe_aux] = likelihood_doc_class(path+\"/\"+file_name, classe_aux)\n",
    "          \n",
    "          if (classe == max(likelihood, key=likelihood.get)):\n",
    "              correct_tests += 1\n",
    "    \n",
    "    return 100*correct_tests/total_documents\n",
    "\n",
    "accuracy = {}\n",
    "\n",
    "for classe in classes:\n",
    "    accuracy[classe] = test(classe, documents_amount['TEST'][classe])\n",
    "    print(f\"\\nAccuracy ({classe}) = {accuracy[classe]}%\")\n",
    "\n",
    "print(f\"\\nAccuracy (average) = {sum(accuracy.values())/len(accuracy)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
